# -*- coding: utf-8 -*-
"""lgistic_regression.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EBcAdND062HOsSyLspKV7df5HzAfMpUz
"""

import numpy as np
import torch
import torchvision
from torchvision.datasets import MNIST
print(torch.__version__)

from google.colab import files
uploaded = files.upload()  # This will allow you to select files from your local machine

import zipfile
import os

# Specify the uploaded zip file's name
zip_filename = "data.zip"

# Create a directory to extract the files into
extracted_folder = "/content/extracted_data"  # You can change this path if needed

# Extract the zip file
with zipfile.ZipFile(zip_filename, 'r') as zip_ref:
    zip_ref.extractall(extracted_folder)

print(f"Files extracted to {extracted_folder}")

# List the files in the extracted folder
extracted_files = os.listdir(extracted_folder)
print(extracted_files)

"""# Image classification using MNSIT data set"""

# Download the dataset
# dataset = MNIST(root ='data/', download = True)

dataset = MNIST(root='extracted_data/data/', train=True, download=False)

dataset

len(dataset)   # there are 6000 images in the dataset, there is also a set of 10,000 images which can be created by passing the train = False to MNIST class

test_dataset = MNIST(root ='extracted_data/data/', train = False)  # 10000 images for the test not for training
len(test_dataset)

# it is a supervsided,so every image in the training data has a labels

# Commented out IPython magic to ensure Python compatibility.
import matplotlib.pyplot as plt  # This imports the plotting library

# This magic command displays plots directly inside the Jupyter Notebook
# %matplotlib inline

# please try to run this line if you are using google colab or other..... on classical notebook it will died/crash your kernel
image, label = dataset[0]
plt.imshow(image,cmap ='gray')
print('label', label)

image, label = dataset[10]
plt.imshow(image,cmap = 'gray')
print('lable',label)

# so the thing is pytrch does not now how to work with images so we need to convert it into the tensors

import torchvision.transforms as transforms

dataset = MNIST(root='extracted_data/data/', train=True, transform= transforms.ToTensor())

img_tensor, label = dataset[0]
print(img_tensor.shape, label)    # the 1 in the output is mean the color (The image has 1 color channel (grayscale).)

# Print a 5x5 sub-region of the image from row 10 to 14 and column 10 to 14
# img_tensor is the tensor representing the image (shape: [1, 28, 28])
# We use slicing to extract a 5x5 part of the image starting from row 10 to 14 and column 10 to 14
print(img_tensor[:, 10:15, 10:15])

# Print the maximum and minimum pixel values in the entire image tensor
# torch.max() returns the maximum pixel value in the image tensor (for MNIST, usually 255)
# torch.min() returns the minimum pixel value in the image tensor (for MNIST, usually 0)
# the values near to 1 is basically white and 0 mean black
print(torch.max(img_tensor), torch.min(img_tensor))

plt.imshow(img_tensor[0,10:15,10:15],cmap ='gray')

# Training and Validation Datasets

# 1. Training Set:
# The training set is the data used to train the machine learning model.
# It consists of labeled examples (inputs and outputs) that the model learns from.
# The goal is for the model to find patterns or relationships in this data so it can make accurate predictions on new data.

# Example: The model sees images of numbers (0-9) along with their labels during training and learns to classify them.

# 2. Validation Set:
# The validation set is a subset of the data that is used to evaluate the model during the training process.
# It helps in tuning the model's hyperparameters (like learning rate, number of epochs, etc.) and checking if the model is overfitting.
# It is separate from the training set and should not be used to train the model.

# Example: After training for a few epochs, the model is tested on the validation set to monitor its performance and adjust hyperparameters if necessary.

# 3. Test Set:
# The test set is a completely separate portion of the data that is used to evaluate the final performance of the model.
# This set is not used during training or validation and provides an unbiased estimate of how well the model performs on unseen data.
# The test set is used only after training and validation are complete.

# Example: After training and tuning the model using the training and validation sets, the model is tested on the test set to see how well it generalizes to new, real-world data.

from torch.utils.data import random_split

train_ds, val_ds = random_split(dataset, [50000, 10000])
len(train_ds), len(val_ds)

from torch.utils.data import DataLoader

batch_size =128

train_loader = DataLoader(train_ds, batch_size, shuffle= True)
val_loader = DataLoader(val_ds,batch_size)

import torch.nn as nn

# The input size of the image is determined based on the shape of each image in the dataset.
# In the MNIST dataset, each image is a 28x28 pixel grayscale image, which gives 28 * 28 = 784 pixels in total.
# This is why we use 28*28 as the input size for the logistic regression model.

input_size = 28 * 28  # Each image has 28x28 pixels, flattened to a vector of length 784
num_classes = 10  # The MNIST dataset has 10 classes (digits 0 to 9)

# Creating a logistic regression model using a single fully connected layer
# The model will take a 784-dimensional input (flattened 28x28 image) and output 10 values (for each digit class)
model = nn.Linear(input_size, num_classes)  # Linear layer with input size and output size (number of classes)

print(model.weight.shape)
model.weight

print(model.bias.shape)
model.bias

class MnistModel(nn.Module):
    def __init__(self):
        super().__init__()
        # Define a fully connected (linear) layer to map input_size to num_classes
        self.Linear = nn.Linear(input_size, num_classes)

    def forward(self, x):
        # Reshape the input 'x' to a 2D tensor where the second dimension is 784 (28x28 pixels flattened)
        xb = x.reshape(-1, 784)  # '-1' means batch size, 784 is the flattened size of 28x28 images

        # Pass the reshaped input through the linear layer
        out = self.Linear(xb)

        return out

# Instantiate the model
model = MnistModel()

for images, label in train_loader:
  print('images.shape:', images.shape)
  outputs = model(images)
  break

print('output.shape:', outputs.shape)
print('sample outputs:\n', outputs[:2].data)

import torch.nn.functional as F

# apply softmax for each output row
probs = F.softmax(outputs, dim = 1)

#look at sample probabilities
print("sample probabilities:\n", probs[:2].data)

#adding up the probabaities of an output row

print("sum:", torch.sum(probs[0]).item())

max_probs,  preds = torch.max(probs, dim =1)
print(preds)

print(max_probs)

# Evaluation Metric and loss function

def accuracy(outputs, labels):
  _, preds = torch.max(outputs,dim = 1)
  return torch.tensor(torch.sum(preds == labels).item()/len(preds))

accuracy(outputs, label)

loss_fn = F.cross_entropy

# loss for current batch of data

loss = loss_fn(outputs,label)
print(loss)

"""**Training Model**"""

class MnistModel(nn.Module):
  def __init__(self):
    super().__init__()
    self.linear = nn.Linear(input_size,num_classes)

  def forward(self, xb):
    xb = xb.reshape(-1,784)
    out = self.linear(xb)
    return out

  def training_step(self, batch):
    images ,labels = batch
    out = self(images)  #generate predication
    loss = F.cross_entropy(out,labels)  # calculate loss

    return loss

  def validation_step(self, batch):
    images, labels = batch
    out = self(images)  #generate predication
    loss = F.cross_entropy(out,labels)  # calculate loss
    acc = accuracy(out,labels)
    return {'val_loss': loss, 'val_acc':acc}


  def validation_epoch_end(self, outputs):
    batch_losses = [x['val_loss'] for x in outputs]
    epoch_loss = torch.stack(batch_losses).mean()   #combine losses
    batch_accs= [x['val_acc']for x in outputs]
    epoch_acc = torch.stack(batch_accs).mean()
    return {'val_loss':epoch_loss.item(),'val_acc':epoch_acc.item()}

  def epoch_end(self,epoch,result):
    print("Epoch[{}], val_loss: {:.4f}, val_acc:{:.4f}".format(epoch, result['val_loss'],result['val_acc']))


model = MnistModel()

def evaluate(model, val_loder):
  outputs =[model.validation_step(batch) for batch in val_loader]
  return model.validation_epoch_end(outputs)


def fit(epochs, lr, model, train_loader, val_loader, opt_func = torch.optim.SGD):
  history = []
  optimizer = opt_func(model.parameters(), lr)
  for epoch in range(epochs):
    #traininng phase
    for batch in train_loader:
      loss = model.training_step(batch)
      loss.backward()
      optimizer.step()
      optimizer.zero_grad()
      #validation phase
      result = evaluate(model, val_loader)
      model.epoch_end(epoch, result)
      history.append(result)

    return history

result0 = evaluate(model, val_loader)
result0

history1 = fit(15, 0.001, model, train_loader,  val_loader)

# replace these values with your results

history = [result0]+history1
accuracies = [result['val_acc']for result in history]

plt.plot(accuracies, 'x')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.title('Accuracy vs.NO.of epochs')

# Define test dataset
test_dataset = MNIST(root='extracted_data/data/', train=False, transform=transforms.ToTensor())

img,label  =test_dataset[0]

plt.imshow(img[0], cmap = 'gray')

print('Shape:', img.shape)
print('Label', label)

img.unsqueeze(0).shape

def predict_image(img, model):
  xb = img.unsqueeze(0)
  yb = model(xb)
  _, preds = torch.max(yb, dim = 1)
  return preds[0].item()

img, label  =test_dataset[0]
plt.imshow(img[0], cmap =('gray'))
print('Label:', label, ', Predicated:', predict_image(img, model))

img, label  =test_dataset[8]
plt.imshow(img[0], cmap =('gray'))
print('Label:', label, ',  Predicated:', predict_image(img, model))

img, label  =test_dataset[6]
plt.imshow(img[0], cmap =('gray'))
print('Label:', label, ', Predicated:', predict_image(img, model))


{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c06e7a3-ca15-4f19-8eff-f11f60a3371f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torch) (75.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\mashita_lab\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "068bee60-7818-4c38-890b-079c56ef7b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0+cpu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e5f184-dd9f-424d-828d-f483ed791e54",
   "metadata": {},
   "source": [
    " # Linear regression using pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6a965b07-4500-44d9-9c21-5d0da75221f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# again the input is temp,rainfall, humidity\n",
    "inputs = np.array([\n",
    "    [ 50,  62, 105],\n",
    "    [ 87,  51, 137],\n",
    "    [118,  78, 120],\n",
    "    [ 88,  71, 121],\n",
    "    [ 89, 109,  44]], dtype= 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b7c277a-6c72-4626-86c4-bbc322feb70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#targets are apples oranges \n",
    "targets = np.array([\n",
    "    [150, 200],  # apples yield: 150, oranges yield: 200 for the first row\n",
    "    [180, 220],  # apples yield: 180, oranges yield: 220 for the second row\n",
    "    [160, 210],  # apples yield: 160, oranges yield: 210 for the third row\n",
    "    [170, 190],  # apples yield: 170, oranges yield: 190 for the fourth row\n",
    "    [165, 195]   # apples yield: 165, oranges yield: 195 for the fifth row\n",
    "], dtype= 'float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1388f164-96cb-4ad8-a764-c07847a7f2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert inputs and targets to tensors\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30ce9aca-2b45-47ae-a819-b2fbf92e7b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1348, -0.9038, -0.3303],\n",
      "        [ 0.8751, -0.3124, -1.3438]], requires_grad=True)\n",
      "tensor([-0.3643,  1.2211], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# now what we are doing is to geneare the random bais and weights\n",
    "\n",
    "w = torch.randn(2,3, requires_grad = True)\n",
    "b = torch.randn(2, requires_grad = True)\n",
    "\n",
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ee4bff02-6671-4bd6-b3bf-927fbcc4b171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x multiply with w transpose and add with b  also @ represent matrix multiplication pytorch\n",
    "\n",
    "def model(x):\n",
    "    return x@ w.t() +b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc18d23b-7ee0-42d3-a11b-0f1c092d3e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -97.8155, -115.4991],\n",
      "        [-103.4297, -122.6876],\n",
      "        [-126.3957,  -81.1512],\n",
      "        [-116.3558, -106.5599],\n",
      "        [-125.4039,  -14.0822]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#generate predication\n",
    "\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec75f59d-f2f4-42b1-ac1c-35dc26cbfd0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[150., 200.],\n",
      "        [180., 220.],\n",
      "        [160., 210.],\n",
      "        [170., 190.],\n",
      "        [165., 195.]])\n"
     ]
    }
   ],
   "source": [
    "# just to see the targets to compare it with the predication how close it is \n",
    "\n",
    "print(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bac0fc82-fcb3-49a9-a0c2-13c0f3724299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(82350.7969, grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# before imporve the model we need to evalaute our model and that is the loss  and the below is mean sqaured error\n",
    "\n",
    "diff =preds - targets\n",
    "torch.sum(diff*diff)/diff.numel()   #element wise multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f78535ae-173a-45c4-ba7d-7f9b091d2a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse (t1,t2):\n",
    "    diff =t1 - t2\n",
    "    return torch.sum(diff* diff)/ diff.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "235e6daa-6100-4dbc-9273-8e2c8915c952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82350.7969, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aee21e78-05d6-4869-9507-5875e774910f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the gradients\n",
    "loss.backward()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "44fa7531-b0e4-41a1-8789-1db2697de11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.1348, -0.9038, -0.3303],\n",
      "        [ 0.8751, -0.3124, -1.3438]], requires_grad=True)\n",
      "tensor([[-24377.8223, -20828.7246, -29328.9609],\n",
      "        [-24930.0430, -20718.7031, -32019.4238]])\n"
     ]
    }
   ],
   "source": [
    "# gradients for weights\n",
    "print (w)\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "52a02a5b-bf83-485f-b63c-bc45b17c978f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -97.8155, -115.4991],\n",
      "        [-103.4297, -122.6876],\n",
      "        [-126.3957,  -81.1512],\n",
      "        [-116.3558, -106.5599],\n",
      "        [-125.4039,  -14.0822]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# adjust the weights bias using gradient descent \n",
    "# 1. generate predicaion\n",
    "# 2. calculate the loss\n",
    "# 3. compute gradients w.r.t the weights and biases\n",
    "# 4. adjust the wieghts by subtracting a small quantity proportinal to the gradient\n",
    "# 5. reset the gradient to zero\n",
    "\n",
    "preds = model(inputs)\n",
    "print(preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dd5fce64-bee1-4cbe-9b79-cfd0d3affa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(82350.7969, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#calculate the loss\n",
    "\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d2b3afe3-784a-436c-b863-3ac614a8276d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-48755.6445, -41657.4492, -58657.9219],\n",
      "        [-49860.0859, -41437.4062, -64038.8477]])\n",
      "tensor([-557.7602, -581.9920])\n"
     ]
    }
   ],
   "source": [
    "#compute gradients\n",
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ddb35510-31e8-4a1d-b88f-5f13c5e8580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust weights ad reset the gradients\n",
    "\n",
    "with torch.no_grad():\n",
    "    w -= w.grad *1e-5\n",
    "    b -= b.grad *1e-5\n",
    "    w.grad.zero_()\n",
    "    b.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d843d1d2-dad7-4b16-83f0-372bd98c7436",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3279, 0.3459, 1.4295],\n",
      "        [2.3709, 0.9307, 0.5773]], requires_grad=True)\n",
      "tensor([-0.3476,  1.2386], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c7a21de3-a118-43c3-b637-3c0b0a75ba34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(19616.2637, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#claculate loss\n",
    "preds =model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a1d6359-4e73-476b-8dc6-0eb4f293f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    " # train for 100 epochs\n",
    "for i in range(100):\n",
    "    preds = model(inputs)\n",
    "    loss = mse(preds, targets)\n",
    "    loss.backward()\n",
    "    with torch.no_grad():\n",
    "        w -= w.grad *1e-5\n",
    "        b -= b.grad *1e-5\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4336f090-6f6b-4132-b1f3-dd8cf1aefc76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(170.2846, grad_fn=<DivBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#calculaet the loss\n",
    "\n",
    "preds = model(inputs)\n",
    "loss = mse(preds, targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cee5e6c0-822e-4b34-81b0-9ffe2f37ce58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[157.9981, 197.0208],\n",
       "        [161.2015, 200.8887],\n",
       "        [173.8664, 212.5071],\n",
       "        [173.4805, 214.2707],\n",
       "        [157.0566, 188.0333]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predications\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ba6b6d8d-1fa0-40e1-b66c-9369b946e76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[150., 200.],\n",
       "        [180., 220.],\n",
       "        [160., 210.],\n",
       "        [170., 190.],\n",
       "        [165., 195.]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e83f2e8-2858-43b9-9b63-bc057aa0447d",
   "metadata": {},
   "source": [
    " # linear regression using pytroch built-ins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "56cc7ce4-90cf-4346-941a-0110a462d26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dfc978a2-c9a2-4b50-98db-98c1cbacda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([\n",
    "    [50,  62, 105],[91,88,64],[87,135,58],\n",
    "    [87,  51, 137],[69,97,78],[73,67,43],\n",
    "    [118,  78, 120],[87,134,58],[102,43,38],\n",
    "    [88,  71, 121],[73,67,43],[91,88,64],\n",
    "    [89, 109,  44],[102,43,55],[69,96,70]],dtype= 'float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3dadebf0-d517-4cf6-8045-9ecf36959fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array([\n",
    "    [120, 75], [140, 80], [110, 65],\n",
    "    [130, 85], [115, 70], [125, 95],\n",
    "    [145, 100], [135, 90], [120, 85],\n",
    "    [110, 65], [125, 70], [115, 60],\n",
    "    [130, 75], [140, 85], [150, 100]\n",
    "], dtype='float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6669defc-b563-4c32-9054-ec29a4a383fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert inputs and targets to tensors\n",
    "\n",
    "inputs = torch.from_numpy(inputs)\n",
    "targets = torch.from_numpy(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d7b9da3d-6da1-4d92-b770-5c27bfbb5241",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the TensorDataset class from PyTorch's torch.utils.data module.\n",
    "# TensorDataset is used to wrap input and target tensors into a dataset object, making it easier to work with them in training.\n",
    "# It allows you to bundle the features (inputs) and labels (targets) together, so they can be accessed in a single object for training.\n",
    "# This is useful when you want to efficiently manage and iterate through your data for model training.\n",
    "\n",
    "from torch.utils.data import TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "330264be-8c05-4028-8a64-5dc58190a904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 50.,  62., 105.],\n",
       "         [ 91.,  88.,  64.],\n",
       "         [ 87., 135.,  58.]]),\n",
       " tensor([[120.,  75.],\n",
       "         [140.,  80.],\n",
       "         [110.,  65.]]))"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = TensorDataset(inputs, targets)\n",
    "train_ds[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e1b87f13-96f0-4306-9585-20fa0be91aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the DataLoader class from PyTorch's torch.utils.data module.\n",
    "# DataLoader is used to load and iterate over datasets in batches, which is useful for training models.\n",
    "# It helps to efficiently manage large datasets by splitting them into smaller batches and optionally shuffling them.\n",
    "# DataLoader also handles the parallel loading of data (via the num_workers parameter) and supports features like batching and shuffling.\n",
    "# This is essential when training models as it improves memory usage and training speed by loading smaller portions of data at a time.\n",
    "\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b92ad6d2-736a-4f67-8215-f52bc850e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds,batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f2bb41a3-fac5-4d92-9e4f-a057c9eab0a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 87., 134.,  58.],\n",
      "        [ 88.,  71., 121.],\n",
      "        [ 73.,  67.,  43.],\n",
      "        [ 87., 135.,  58.],\n",
      "        [ 89., 109.,  44.]])\n",
      "tensor([[135.,  90.],\n",
      "        [110.,  65.],\n",
      "        [125.,  95.],\n",
      "        [110.,  65.],\n",
      "        [130.,  75.]])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    print(xb)\n",
    "    print(yb)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "92991ae3-24ce-41ae-b1c5-fc64cf71e9e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1594, -0.1415, -0.2368],\n",
      "        [-0.5615, -0.4372, -0.2729]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.5543, -0.4733], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "#define model\n",
    "# Define a simple neural network model with one linear layer.\n",
    "# nn.Linear(input_features, output_features)\n",
    "model =nn.Linear(3,2)\n",
    "print(model.weight)\n",
    "print(model.bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b4a8fa89-b1f3-40b6-a3b7-ae59a34fdb45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1594, -0.1415, -0.2368],\n",
       "         [-0.5615, -0.4372, -0.2729]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.5543, -0.4733], requires_grad=True)]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())  #contins lisst and contins the weights and bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "c6c67618-886c-4eef-8afc-25adcbd9d78b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ -41.0522,  -84.3111],\n",
      "        [ -41.5600, -107.5102],\n",
      "        [ -46.1535, -124.1756],\n",
      "        [ -52.9703, -109.0104],\n",
      "        [ -42.6415, -102.9130],\n",
      "        [ -30.7463,  -82.4907],\n",
      "        [ -57.7081, -133.5818],\n",
      "        [ -46.0119, -123.7383],\n",
      "        [ -30.7886,  -86.9165],\n",
      "        [ -52.1719, -113.9494],\n",
      "        [ -30.7463,  -82.4907],\n",
      "        [ -41.5600, -107.5102],\n",
      "        [ -39.4778, -110.1103],\n",
      "        [ -34.8138,  -91.5561],\n",
      "        [ -40.6058, -100.2925]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "#genearte predication\n",
    "preds = model(inputs)\n",
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "12b84fcb-a6d0-4478-8013-387d9bbaaf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss functiom\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#define the loss function\n",
    "loss_fn = F.mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "45126018-5017-4239-906c-cd374a86afcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(31573.5254, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "loss = loss_fn(model(inputs),targets)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "1dafeb11-733b-4dae-946a-4a191e8c0e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer\n",
    "\n",
    "#define the optimizwr \n",
    "opt = torch.optim.SGD(model.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "9a0e31d1-cc5c-4fae-9e33-56884c28c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to train the model for a specified number of epochs\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    # Iterate over the number of epochs (e.g., 100)\n",
    "    for epoch in range(num_epochs):\n",
    "        # Iterate over batches of data from the training data loader (train_dl)\n",
    "        for xb, yb in train_dl:\n",
    "            # Forward pass: compute the predicted values using the model\n",
    "            pred = model(xb)\n",
    "            \n",
    "            # Compute the loss (error) between predicted values and actual target values (yb)\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # Backpropagate the error (compute gradients for the model parameters)\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the model parameters using the optimizer\n",
    "            opt.step()\n",
    "            \n",
    "            # Zero the gradients after the update to prepare for the next iteration\n",
    "            opt.zero_grad()\n",
    "        \n",
    "        # Every 10 epochs, print the current epoch and the loss value\n",
    "        print('Epoch [{}/{}], Loss:{:.4f}'.format(epoch+1, num_epochs, loss.item()))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "783b7896-7e43-4b3f-ab55-f11efa07448a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/400], Loss:473.7966\n",
      "Epoch [2/400], Loss:279.5580\n",
      "Epoch [3/400], Loss:144.7926\n",
      "Epoch [4/400], Loss:421.1958\n",
      "Epoch [5/400], Loss:423.2240\n",
      "Epoch [6/400], Loss:499.7539\n",
      "Epoch [7/400], Loss:277.2403\n",
      "Epoch [8/400], Loss:466.9181\n",
      "Epoch [9/400], Loss:168.4995\n",
      "Epoch [10/400], Loss:162.2524\n",
      "Epoch [11/400], Loss:254.2240\n",
      "Epoch [12/400], Loss:550.2134\n",
      "Epoch [13/400], Loss:163.2447\n",
      "Epoch [14/400], Loss:328.2859\n",
      "Epoch [15/400], Loss:537.1932\n",
      "Epoch [16/400], Loss:225.8770\n",
      "Epoch [17/400], Loss:306.0306\n",
      "Epoch [18/400], Loss:404.5529\n",
      "Epoch [19/400], Loss:269.7166\n",
      "Epoch [20/400], Loss:174.3310\n",
      "Epoch [21/400], Loss:361.7229\n",
      "Epoch [22/400], Loss:109.4663\n",
      "Epoch [23/400], Loss:509.7591\n",
      "Epoch [24/400], Loss:474.1230\n",
      "Epoch [25/400], Loss:281.4485\n",
      "Epoch [26/400], Loss:344.8466\n",
      "Epoch [27/400], Loss:290.5508\n",
      "Epoch [28/400], Loss:359.0347\n",
      "Epoch [29/400], Loss:465.5396\n",
      "Epoch [30/400], Loss:530.6081\n",
      "Epoch [31/400], Loss:188.7867\n",
      "Epoch [32/400], Loss:415.6129\n",
      "Epoch [33/400], Loss:387.2535\n",
      "Epoch [34/400], Loss:405.8904\n",
      "Epoch [35/400], Loss:285.4509\n",
      "Epoch [36/400], Loss:169.5284\n",
      "Epoch [37/400], Loss:489.6771\n",
      "Epoch [38/400], Loss:219.6150\n",
      "Epoch [39/400], Loss:209.3372\n",
      "Epoch [40/400], Loss:530.2814\n",
      "Epoch [41/400], Loss:255.2627\n",
      "Epoch [42/400], Loss:249.8532\n",
      "Epoch [43/400], Loss:270.2873\n",
      "Epoch [44/400], Loss:445.3213\n",
      "Epoch [45/400], Loss:139.4606\n",
      "Epoch [46/400], Loss:230.1536\n",
      "Epoch [47/400], Loss:342.0070\n",
      "Epoch [48/400], Loss:702.9210\n",
      "Epoch [49/400], Loss:405.8919\n",
      "Epoch [50/400], Loss:429.9974\n",
      "Epoch [51/400], Loss:306.6155\n",
      "Epoch [52/400], Loss:445.8524\n",
      "Epoch [53/400], Loss:148.2751\n",
      "Epoch [54/400], Loss:475.8607\n",
      "Epoch [55/400], Loss:414.3745\n",
      "Epoch [56/400], Loss:375.8290\n",
      "Epoch [57/400], Loss:377.6972\n",
      "Epoch [58/400], Loss:217.8583\n",
      "Epoch [59/400], Loss:505.1526\n",
      "Epoch [60/400], Loss:259.5773\n",
      "Epoch [61/400], Loss:198.8710\n",
      "Epoch [62/400], Loss:343.0175\n",
      "Epoch [63/400], Loss:423.3712\n",
      "Epoch [64/400], Loss:329.1266\n",
      "Epoch [65/400], Loss:329.3884\n",
      "Epoch [66/400], Loss:284.8128\n",
      "Epoch [67/400], Loss:628.3057\n",
      "Epoch [68/400], Loss:312.3311\n",
      "Epoch [69/400], Loss:120.5770\n",
      "Epoch [70/400], Loss:668.1869\n",
      "Epoch [71/400], Loss:250.4327\n",
      "Epoch [72/400], Loss:84.2493\n",
      "Epoch [73/400], Loss:482.4895\n",
      "Epoch [74/400], Loss:300.0832\n",
      "Epoch [75/400], Loss:385.1320\n",
      "Epoch [76/400], Loss:512.2552\n",
      "Epoch [77/400], Loss:437.3225\n",
      "Epoch [78/400], Loss:308.6950\n",
      "Epoch [79/400], Loss:203.1149\n",
      "Epoch [80/400], Loss:333.1837\n",
      "Epoch [81/400], Loss:229.0182\n",
      "Epoch [82/400], Loss:467.9426\n",
      "Epoch [83/400], Loss:467.9157\n",
      "Epoch [84/400], Loss:366.3740\n",
      "Epoch [85/400], Loss:244.5292\n",
      "Epoch [86/400], Loss:479.7048\n",
      "Epoch [87/400], Loss:310.1492\n",
      "Epoch [88/400], Loss:430.7614\n",
      "Epoch [89/400], Loss:229.7495\n",
      "Epoch [90/400], Loss:263.1982\n",
      "Epoch [91/400], Loss:226.1391\n",
      "Epoch [92/400], Loss:463.1305\n",
      "Epoch [93/400], Loss:564.4562\n",
      "Epoch [94/400], Loss:281.0717\n",
      "Epoch [95/400], Loss:226.6100\n",
      "Epoch [96/400], Loss:279.1227\n",
      "Epoch [97/400], Loss:481.6982\n",
      "Epoch [98/400], Loss:528.8936\n",
      "Epoch [99/400], Loss:357.3661\n",
      "Epoch [100/400], Loss:199.3758\n",
      "Epoch [101/400], Loss:149.6862\n",
      "Epoch [102/400], Loss:357.0363\n",
      "Epoch [103/400], Loss:88.4621\n",
      "Epoch [104/400], Loss:331.0448\n",
      "Epoch [105/400], Loss:438.8876\n",
      "Epoch [106/400], Loss:310.5941\n",
      "Epoch [107/400], Loss:400.0143\n",
      "Epoch [108/400], Loss:575.6769\n",
      "Epoch [109/400], Loss:658.1442\n",
      "Epoch [110/400], Loss:168.1528\n",
      "Epoch [111/400], Loss:290.5376\n",
      "Epoch [112/400], Loss:486.7181\n",
      "Epoch [113/400], Loss:346.3707\n",
      "Epoch [114/400], Loss:177.5136\n",
      "Epoch [115/400], Loss:376.1337\n",
      "Epoch [116/400], Loss:262.6823\n",
      "Epoch [117/400], Loss:422.4003\n",
      "Epoch [118/400], Loss:194.2420\n",
      "Epoch [119/400], Loss:344.8398\n",
      "Epoch [120/400], Loss:530.3046\n",
      "Epoch [121/400], Loss:344.3432\n",
      "Epoch [122/400], Loss:253.0654\n",
      "Epoch [123/400], Loss:232.9848\n",
      "Epoch [124/400], Loss:265.6517\n",
      "Epoch [125/400], Loss:236.7477\n",
      "Epoch [126/400], Loss:259.7710\n",
      "Epoch [127/400], Loss:258.3584\n",
      "Epoch [128/400], Loss:215.7464\n",
      "Epoch [129/400], Loss:386.9089\n",
      "Epoch [130/400], Loss:416.0886\n",
      "Epoch [131/400], Loss:201.7693\n",
      "Epoch [132/400], Loss:262.6386\n",
      "Epoch [133/400], Loss:308.6979\n",
      "Epoch [134/400], Loss:217.1912\n",
      "Epoch [135/400], Loss:193.8553\n",
      "Epoch [136/400], Loss:292.9850\n",
      "Epoch [137/400], Loss:232.8384\n",
      "Epoch [138/400], Loss:544.6483\n",
      "Epoch [139/400], Loss:477.1847\n",
      "Epoch [140/400], Loss:548.9776\n",
      "Epoch [141/400], Loss:259.9962\n",
      "Epoch [142/400], Loss:320.4215\n",
      "Epoch [143/400], Loss:280.5320\n",
      "Epoch [144/400], Loss:372.8062\n",
      "Epoch [145/400], Loss:161.4818\n",
      "Epoch [146/400], Loss:373.4555\n",
      "Epoch [147/400], Loss:347.6471\n",
      "Epoch [148/400], Loss:593.8063\n",
      "Epoch [149/400], Loss:248.9680\n",
      "Epoch [150/400], Loss:388.4804\n",
      "Epoch [151/400], Loss:513.1332\n",
      "Epoch [152/400], Loss:293.7669\n",
      "Epoch [153/400], Loss:600.6801\n",
      "Epoch [154/400], Loss:197.8882\n",
      "Epoch [155/400], Loss:309.7187\n",
      "Epoch [156/400], Loss:111.2974\n",
      "Epoch [157/400], Loss:538.7927\n",
      "Epoch [158/400], Loss:478.1682\n",
      "Epoch [159/400], Loss:353.2908\n",
      "Epoch [160/400], Loss:430.7982\n",
      "Epoch [161/400], Loss:271.0545\n",
      "Epoch [162/400], Loss:435.9955\n",
      "Epoch [163/400], Loss:446.4273\n",
      "Epoch [164/400], Loss:282.2809\n",
      "Epoch [165/400], Loss:280.7220\n",
      "Epoch [166/400], Loss:175.4496\n",
      "Epoch [167/400], Loss:327.7721\n",
      "Epoch [168/400], Loss:177.2186\n",
      "Epoch [169/400], Loss:230.0554\n",
      "Epoch [170/400], Loss:420.2274\n",
      "Epoch [171/400], Loss:206.8650\n",
      "Epoch [172/400], Loss:455.1118\n",
      "Epoch [173/400], Loss:346.4519\n",
      "Epoch [174/400], Loss:289.4250\n",
      "Epoch [175/400], Loss:506.6723\n",
      "Epoch [176/400], Loss:259.6021\n",
      "Epoch [177/400], Loss:223.6376\n",
      "Epoch [178/400], Loss:249.4306\n",
      "Epoch [179/400], Loss:470.1682\n",
      "Epoch [180/400], Loss:315.0986\n",
      "Epoch [181/400], Loss:243.5737\n",
      "Epoch [182/400], Loss:104.8558\n",
      "Epoch [183/400], Loss:412.4208\n",
      "Epoch [184/400], Loss:274.1787\n",
      "Epoch [185/400], Loss:308.2134\n",
      "Epoch [186/400], Loss:491.6620\n",
      "Epoch [187/400], Loss:385.9352\n",
      "Epoch [188/400], Loss:476.5588\n",
      "Epoch [189/400], Loss:206.7625\n",
      "Epoch [190/400], Loss:446.6678\n",
      "Epoch [191/400], Loss:305.0191\n",
      "Epoch [192/400], Loss:232.5278\n",
      "Epoch [193/400], Loss:303.4176\n",
      "Epoch [194/400], Loss:433.9320\n",
      "Epoch [195/400], Loss:411.7130\n",
      "Epoch [196/400], Loss:261.9324\n",
      "Epoch [197/400], Loss:411.1013\n",
      "Epoch [198/400], Loss:351.7693\n",
      "Epoch [199/400], Loss:160.1652\n",
      "Epoch [200/400], Loss:400.8798\n",
      "Epoch [201/400], Loss:135.8522\n",
      "Epoch [202/400], Loss:546.3195\n",
      "Epoch [203/400], Loss:241.1411\n",
      "Epoch [204/400], Loss:382.2129\n",
      "Epoch [205/400], Loss:428.5742\n",
      "Epoch [206/400], Loss:354.9253\n",
      "Epoch [207/400], Loss:585.3149\n",
      "Epoch [208/400], Loss:250.4091\n",
      "Epoch [209/400], Loss:566.7202\n",
      "Epoch [210/400], Loss:362.6040\n",
      "Epoch [211/400], Loss:349.0644\n",
      "Epoch [212/400], Loss:224.0213\n",
      "Epoch [213/400], Loss:357.3739\n",
      "Epoch [214/400], Loss:287.0494\n",
      "Epoch [215/400], Loss:513.6501\n",
      "Epoch [216/400], Loss:336.5490\n",
      "Epoch [217/400], Loss:491.1053\n",
      "Epoch [218/400], Loss:417.4744\n",
      "Epoch [219/400], Loss:338.7072\n",
      "Epoch [220/400], Loss:258.0032\n",
      "Epoch [221/400], Loss:262.3051\n",
      "Epoch [222/400], Loss:312.6074\n",
      "Epoch [223/400], Loss:260.9519\n",
      "Epoch [224/400], Loss:469.7987\n",
      "Epoch [225/400], Loss:345.6094\n",
      "Epoch [226/400], Loss:422.5369\n",
      "Epoch [227/400], Loss:399.6396\n",
      "Epoch [228/400], Loss:216.9607\n",
      "Epoch [229/400], Loss:189.1740\n",
      "Epoch [230/400], Loss:236.3090\n",
      "Epoch [231/400], Loss:423.3302\n",
      "Epoch [232/400], Loss:421.3989\n",
      "Epoch [233/400], Loss:293.2408\n",
      "Epoch [234/400], Loss:444.7653\n",
      "Epoch [235/400], Loss:144.2693\n",
      "Epoch [236/400], Loss:17.3144\n",
      "Epoch [237/400], Loss:536.3643\n",
      "Epoch [238/400], Loss:297.9873\n",
      "Epoch [239/400], Loss:380.0924\n",
      "Epoch [240/400], Loss:347.5959\n",
      "Epoch [241/400], Loss:525.5704\n",
      "Epoch [242/400], Loss:358.3690\n",
      "Epoch [243/400], Loss:203.0934\n",
      "Epoch [244/400], Loss:496.4357\n",
      "Epoch [245/400], Loss:256.8854\n",
      "Epoch [246/400], Loss:557.7057\n",
      "Epoch [247/400], Loss:263.7088\n",
      "Epoch [248/400], Loss:220.7755\n",
      "Epoch [249/400], Loss:160.6297\n",
      "Epoch [250/400], Loss:367.4677\n",
      "Epoch [251/400], Loss:277.7362\n",
      "Epoch [252/400], Loss:231.4853\n",
      "Epoch [253/400], Loss:150.4015\n",
      "Epoch [254/400], Loss:292.5028\n",
      "Epoch [255/400], Loss:284.5497\n",
      "Epoch [256/400], Loss:484.3303\n",
      "Epoch [257/400], Loss:143.4192\n",
      "Epoch [258/400], Loss:320.4083\n",
      "Epoch [259/400], Loss:324.8026\n",
      "Epoch [260/400], Loss:514.7040\n",
      "Epoch [261/400], Loss:499.8299\n",
      "Epoch [262/400], Loss:475.4066\n",
      "Epoch [263/400], Loss:524.1906\n",
      "Epoch [264/400], Loss:394.4665\n",
      "Epoch [265/400], Loss:450.1054\n",
      "Epoch [266/400], Loss:255.7793\n",
      "Epoch [267/400], Loss:367.4069\n",
      "Epoch [268/400], Loss:357.2480\n",
      "Epoch [269/400], Loss:78.3150\n",
      "Epoch [270/400], Loss:206.5976\n",
      "Epoch [271/400], Loss:215.9760\n",
      "Epoch [272/400], Loss:287.6168\n",
      "Epoch [273/400], Loss:370.2498\n",
      "Epoch [274/400], Loss:328.5172\n",
      "Epoch [275/400], Loss:266.2971\n",
      "Epoch [276/400], Loss:375.2953\n",
      "Epoch [277/400], Loss:42.1977\n",
      "Epoch [278/400], Loss:377.4428\n",
      "Epoch [279/400], Loss:187.2710\n",
      "Epoch [280/400], Loss:384.2422\n",
      "Epoch [281/400], Loss:229.4843\n",
      "Epoch [282/400], Loss:95.3970\n",
      "Epoch [283/400], Loss:521.9279\n",
      "Epoch [284/400], Loss:416.7562\n",
      "Epoch [285/400], Loss:400.7305\n",
      "Epoch [286/400], Loss:314.8781\n",
      "Epoch [287/400], Loss:503.2863\n",
      "Epoch [288/400], Loss:293.4320\n",
      "Epoch [289/400], Loss:362.6500\n",
      "Epoch [290/400], Loss:88.6995\n",
      "Epoch [291/400], Loss:325.9752\n",
      "Epoch [292/400], Loss:298.1895\n",
      "Epoch [293/400], Loss:502.9359\n",
      "Epoch [294/400], Loss:393.3737\n",
      "Epoch [295/400], Loss:351.9705\n",
      "Epoch [296/400], Loss:373.2529\n",
      "Epoch [297/400], Loss:447.6649\n",
      "Epoch [298/400], Loss:311.8688\n",
      "Epoch [299/400], Loss:140.7304\n",
      "Epoch [300/400], Loss:369.2363\n",
      "Epoch [301/400], Loss:589.1632\n",
      "Epoch [302/400], Loss:317.2248\n",
      "Epoch [303/400], Loss:427.0450\n",
      "Epoch [304/400], Loss:234.7940\n",
      "Epoch [305/400], Loss:156.9230\n",
      "Epoch [306/400], Loss:403.5703\n",
      "Epoch [307/400], Loss:90.7807\n",
      "Epoch [308/400], Loss:417.6129\n",
      "Epoch [309/400], Loss:578.1107\n",
      "Epoch [310/400], Loss:246.7612\n",
      "Epoch [311/400], Loss:363.9804\n",
      "Epoch [312/400], Loss:244.5406\n",
      "Epoch [313/400], Loss:258.9155\n",
      "Epoch [314/400], Loss:313.1621\n",
      "Epoch [315/400], Loss:315.7296\n",
      "Epoch [316/400], Loss:443.0711\n",
      "Epoch [317/400], Loss:499.5401\n",
      "Epoch [318/400], Loss:540.4766\n",
      "Epoch [319/400], Loss:451.8643\n",
      "Epoch [320/400], Loss:247.5611\n",
      "Epoch [321/400], Loss:318.8483\n",
      "Epoch [322/400], Loss:399.9395\n",
      "Epoch [323/400], Loss:342.8365\n",
      "Epoch [324/400], Loss:290.5762\n",
      "Epoch [325/400], Loss:182.0955\n",
      "Epoch [326/400], Loss:245.4826\n",
      "Epoch [327/400], Loss:385.4215\n",
      "Epoch [328/400], Loss:460.2719\n",
      "Epoch [329/400], Loss:335.4545\n",
      "Epoch [330/400], Loss:304.6405\n",
      "Epoch [331/400], Loss:146.8440\n",
      "Epoch [332/400], Loss:381.3784\n",
      "Epoch [333/400], Loss:459.2003\n",
      "Epoch [334/400], Loss:347.0913\n",
      "Epoch [335/400], Loss:191.3970\n",
      "Epoch [336/400], Loss:248.9535\n",
      "Epoch [337/400], Loss:267.4114\n",
      "Epoch [338/400], Loss:658.2529\n",
      "Epoch [339/400], Loss:324.3889\n",
      "Epoch [340/400], Loss:333.8857\n",
      "Epoch [341/400], Loss:130.1935\n",
      "Epoch [342/400], Loss:394.9488\n",
      "Epoch [343/400], Loss:333.5939\n",
      "Epoch [344/400], Loss:412.1871\n",
      "Epoch [345/400], Loss:421.1343\n",
      "Epoch [346/400], Loss:359.7552\n",
      "Epoch [347/400], Loss:343.4432\n",
      "Epoch [348/400], Loss:389.4601\n",
      "Epoch [349/400], Loss:200.4008\n",
      "Epoch [350/400], Loss:219.4955\n",
      "Epoch [351/400], Loss:403.4989\n",
      "Epoch [352/400], Loss:86.5611\n",
      "Epoch [353/400], Loss:416.8952\n",
      "Epoch [354/400], Loss:365.6525\n",
      "Epoch [355/400], Loss:530.8923\n",
      "Epoch [356/400], Loss:584.0583\n",
      "Epoch [357/400], Loss:372.7403\n",
      "Epoch [358/400], Loss:494.7534\n",
      "Epoch [359/400], Loss:416.6734\n",
      "Epoch [360/400], Loss:415.6538\n",
      "Epoch [361/400], Loss:231.2611\n",
      "Epoch [362/400], Loss:522.1686\n",
      "Epoch [363/400], Loss:413.5805\n",
      "Epoch [364/400], Loss:202.1265\n",
      "Epoch [365/400], Loss:391.4490\n",
      "Epoch [366/400], Loss:170.7606\n",
      "Epoch [367/400], Loss:151.8363\n",
      "Epoch [368/400], Loss:290.6712\n",
      "Epoch [369/400], Loss:121.2190\n",
      "Epoch [370/400], Loss:523.9016\n",
      "Epoch [371/400], Loss:248.4192\n",
      "Epoch [372/400], Loss:303.0017\n",
      "Epoch [373/400], Loss:112.7360\n",
      "Epoch [374/400], Loss:306.5722\n",
      "Epoch [375/400], Loss:406.0444\n",
      "Epoch [376/400], Loss:352.4442\n",
      "Epoch [377/400], Loss:304.4293\n",
      "Epoch [378/400], Loss:270.1935\n",
      "Epoch [379/400], Loss:341.2713\n",
      "Epoch [380/400], Loss:439.1246\n",
      "Epoch [381/400], Loss:306.2894\n",
      "Epoch [382/400], Loss:472.4149\n",
      "Epoch [383/400], Loss:196.6289\n",
      "Epoch [384/400], Loss:196.9358\n",
      "Epoch [385/400], Loss:318.4803\n",
      "Epoch [386/400], Loss:384.4710\n",
      "Epoch [387/400], Loss:369.9602\n",
      "Epoch [388/400], Loss:433.6335\n",
      "Epoch [389/400], Loss:200.9570\n",
      "Epoch [390/400], Loss:509.6360\n",
      "Epoch [391/400], Loss:318.5420\n",
      "Epoch [392/400], Loss:238.6362\n",
      "Epoch [393/400], Loss:521.3253\n",
      "Epoch [394/400], Loss:95.4847\n",
      "Epoch [395/400], Loss:331.4313\n",
      "Epoch [396/400], Loss:290.1557\n",
      "Epoch [397/400], Loss:278.9492\n",
      "Epoch [398/400], Loss:591.0255\n",
      "Epoch [399/400], Loss:330.5260\n",
      "Epoch [400/400], Loss:162.7833\n"
     ]
    }
   ],
   "source": [
    "fit(400, model, loss_fn, opt, train_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d80fab08-a4d4-4ac6-8624-37db266518f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 91.0131,  56.7913],\n",
       "        [130.2580,  81.5608],\n",
       "        [139.4335,  84.9063],\n",
       "        [130.6523,  84.1496],\n",
       "        [114.5048,  70.4503],\n",
       "        [101.7566,  63.6240],\n",
       "        [165.5640, 105.9811],\n",
       "        [139.1278,  84.7607],\n",
       "        [121.6900,  78.4568],\n",
       "        [134.3212,  85.3951],\n",
       "        [101.7566,  63.6240],\n",
       "        [130.2580,  81.5608],\n",
       "        [130.4454,  80.3995],\n",
       "        [125.3262,  80.9267],\n",
       "        [112.4880,  69.1424]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = model(inputs)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "84dab5d2-79c3-4e77-9c75-50921ccc9d8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[120.,  75.],\n",
       "        [140.,  80.],\n",
       "        [110.,  65.],\n",
       "        [130.,  85.],\n",
       "        [115.,  70.],\n",
       "        [125.,  95.],\n",
       "        [145., 100.],\n",
       "        [135.,  90.],\n",
       "        [120.,  85.],\n",
       "        [110.,  65.],\n",
       "        [125.,  70.],\n",
       "        [115.,  60.],\n",
       "        [130.,  75.],\n",
       "        [140.,  85.],\n",
       "        [150., 100.]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699bd46f-1485-4eee-85d2-09eaa2602af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
